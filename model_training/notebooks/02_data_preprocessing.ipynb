{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfraOwl Data Preprocessing\n",
    "\n",
    "This notebook handles data preprocessing for the InfraOwl model training pipeline.\n",
    "\n",
    "## Tasks\n",
    "- Load and validate raw data\n",
    "- Split data into train/validation/test sets\n",
    "- Resize and normalize images\n",
    "- Apply data augmentation\n",
    "- Generate preprocessing statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import our preprocessing module\n",
    "from data_preprocessing import DataPreprocessor\n",
    "\n",
    "print(\"üîÑ InfraOwl Data Preprocessing Notebook\")\n",
    "print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../configs/training_config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Training Configuration:\")\n",
    "print(f\"  Classes: {config['classes']}\")\n",
    "print(f\"  Target Size: {config['data']['preprocessing']['target_size']}\")\n",
    "print(f\"  Train Split: {config['data']['train_split']}\")\n",
    "print(f\"  Validation Split: {config['data']['val_split']}\")\n",
    "print(f\"  Test Split: {config['data']['test_split']}\")\n",
    "print(f\"  Data Augmentation: {config['data']['augmentation']['enabled']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor('../configs/training_config.yaml')\n",
    "\n",
    "# Validate raw data\n",
    "print(\"üîç Validating raw data...\")\n",
    "try:\n",
    "    raw_stats = preprocessor.validate_raw_data()\n",
    "    print(\"‚úÖ Raw data validation completed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Raw data validation failed: {e}\")\n",
    "    print(\"\\nPlease ensure images are properly organized in:\")\n",
    "    for class_name in config['classes']:\n",
    "        print(f\"  - ../data/raw_images/{class_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize splitting strategy\n",
    "train_split = config['data']['train_split']\n",
    "val_split = config['data']['val_split']\n",
    "test_split = 1 - train_split - val_split\n",
    "\n",
    "# Create pie chart\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Split visualization\n",
    "splits = [train_split, val_split, test_split]\n",
    "labels = ['Train', 'Validation', 'Test']\n",
    "colors = ['#FF9999', '#66B2FF', '#99FF99']\n",
    "\n",
    "ax1.pie(splits, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Data Split Strategy')\n",
    "\n",
    "# Expected sample counts (if we have raw stats)\n",
    "if 'raw_stats' in locals():\n",
    "    expected_counts = {}\n",
    "    class_names = list(raw_stats.keys())\n",
    "    \n",
    "    for split_name, split_ratio in zip(['Train', 'Validation', 'Test'], splits):\n",
    "        expected_counts[split_name] = [int(raw_stats[class_name] * split_ratio) \n",
    "                                     for class_name in class_names]\n",
    "    \n",
    "    # Stacked bar chart\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.6\n",
    "    \n",
    "    bottom_train = np.zeros(len(class_names))\n",
    "    bottom_val = expected_counts['Train']\n",
    "    bottom_test = np.array(expected_counts['Train']) + np.array(expected_counts['Validation'])\n",
    "    \n",
    "    ax2.bar(x, expected_counts['Train'], width, label='Train', color=colors[0])\n",
    "    ax2.bar(x, expected_counts['Validation'], width, bottom=bottom_val, label='Validation', color=colors[1])\n",
    "    ax2.bar(x, expected_counts['Test'], width, bottom=bottom_test, label='Test', color=colors[2])\n",
    "    \n",
    "    ax2.set_xlabel('Classes')\n",
    "    ax2.set_ylabel('Number of Images')\n",
    "    ax2.set_title('Expected Samples per Class')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(class_names, rotation=45)\n",
    "    ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate image preprocessing\n",
    "def show_preprocessing_example():\n",
    "    \"\"\"Show before/after example of image preprocessing.\"\"\"\n",
    "    \n",
    "    # Find a sample image\n",
    "    raw_data_path = Path('../data/raw_images')\n",
    "    sample_image = None\n",
    "    \n",
    "    for class_name in config['classes']:\n",
    "        class_dir = raw_data_path / class_name\n",
    "        if class_dir.exists():\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "                image_files = list(class_dir.glob(ext))\n",
    "                if image_files:\n",
    "                    sample_image = image_files[0]\n",
    "                    break\n",
    "        if sample_image:\n",
    "            break\n",
    "    \n",
    "    if not sample_image:\n",
    "        print(\"No sample images found for preprocessing demo\")\n",
    "        return\n",
    "    \n",
    "    # Load and process image\n",
    "    print(f\"üì∏ Processing sample image: {sample_image.name}\")\n",
    "    \n",
    "    # Original image\n",
    "    original_img = Image.open(sample_image)\n",
    "    \n",
    "    # Processed image (simulate preprocessing)\n",
    "    target_size = tuple(config['data']['preprocessing']['target_size'])\n",
    "    \n",
    "    # Create processed version\n",
    "    processed_img = original_img.copy()\n",
    "    if processed_img.mode != 'RGB':\n",
    "        processed_img = processed_img.convert('RGB')\n",
    "    \n",
    "    # Resize maintaining aspect ratio, then center crop\n",
    "    processed_img.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Create new image with target size\n",
    "    final_img = Image.new('RGB', target_size, (0, 0, 0))\n",
    "    paste_x = (target_size[0] - processed_img.width) // 2\n",
    "    paste_y = (target_size[1] - processed_img.height) // 2\n",
    "    final_img.paste(processed_img, (paste_x, paste_y))\n",
    "    \n",
    "    # Display comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    ax1.imshow(original_img)\n",
    "    ax1.set_title(f'Original\\n{original_img.size[0]} x {original_img.size[1]}')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(final_img)\n",
    "    ax2.set_title(f'Processed\\n{final_img.size[0]} x {final_img.size[1]}')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.suptitle('Image Preprocessing Example')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Original size: {original_img.size}\")\n",
    "    print(f\"Target size: {target_size}\")\n",
    "    print(f\"Final size: {final_img.size}\")\n",
    "\n",
    "show_preprocessing_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete preprocessing pipeline\n",
    "print(\"üöÄ Running complete data preprocessing pipeline...\")\n",
    "print(\"This may take a few minutes depending on dataset size.\\n\")\n",
    "\n",
    "try:\n",
    "    # Run preprocessing\n",
    "    processed_stats = preprocessor.split_and_process_data()\n",
    "    \n",
    "    print(\"\\n‚úÖ Data preprocessing completed successfully!\")\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìä Processing Results:\")\n",
    "    for split_name in ['train', 'validation', 'test']:\n",
    "        total = sum(processed_stats[split_name].values())\n",
    "        print(f\"  {split_name.capitalize()}: {total} images\")\n",
    "        for class_name, count in processed_stats[split_name].items():\n",
    "            print(f\"    {class_name}: {count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Preprocessing failed: {e}\")\n",
    "    processed_stats = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Statistics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate statistics if preprocessing was successful\n",
    "if processed_stats:\n",
    "    print(\"üìà Generating statistics and visualizations...\")\n",
    "    \n",
    "    try:\n",
    "        preprocessor.generate_statistics(processed_stats)\n",
    "        print(\"‚úÖ Statistics generated successfully!\")\n",
    "        \n",
    "        # Display the generated plot\n",
    "        stats_plot_path = Path('../outputs/dataset_statistics.png')\n",
    "        if stats_plot_path.exists():\n",
    "            from IPython.display import Image as IPImage, display\n",
    "            print(\"\\nüìä Dataset Statistics:\")\n",
    "            display(IPImage(filename=str(stats_plot_path)))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Statistics generation failed: {e}\")\nelse:\n",
    "    print(\"‚è≠Ô∏è  Skipping statistics generation (preprocessing not completed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Augmentation Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data augmentation examples\n",
    "def show_augmentation_examples():\n",
    "    \"\"\"Demonstrate data augmentation techniques.\"\"\"\n",
    "    \n",
    "    if not config['data']['augmentation']['enabled']:\n",
    "        print(\"‚ÑπÔ∏è  Data augmentation is disabled in configuration\")\n",
    "        return\n",
    "    \n",
    "    # Find a processed image\n",
    "    processed_path = Path('../data/processed/train')\n",
    "    if not processed_path.exists():\n",
    "        print(\"‚ÑπÔ∏è  No processed data found. Run preprocessing first.\")\n",
    "        return\n",
    "    \n",
    "    sample_image = None\n",
    "    for class_name in config['classes']:\n",
    "        class_dir = processed_path / class_name\n",
    "        if class_dir.exists():\n",
    "            image_files = list(class_dir.glob('*.jpg'))\n",
    "            if image_files:\n",
    "                sample_image = image_files[0]\n",
    "                break\n",
    "    \n",
    "    if not sample_image:\n",
    "        print(\"No processed images found for augmentation demo\")\n",
    "        return\n",
    "    \n",
    "    # Load image\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "    import numpy as np\n",
    "    \n",
    "    img = load_img(sample_image)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "    \n",
    "    # Create augmentation generator\n",
    "    aug_config = config['data']['augmentation']\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=aug_config['rotation_range'],\n",
    "        width_shift_range=aug_config['width_shift_range'],\n",
    "        height_shift_range=aug_config['height_shift_range'],\n",
    "        shear_range=aug_config['shear_range'],\n",
    "        zoom_range=aug_config['zoom_range'],\n",
    "        horizontal_flip=aug_config['horizontal_flip'],\n",
    "        brightness_range=aug_config['brightness_range'],\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Generate augmented examples\n",
    "    print(f\"üîÑ Data Augmentation Examples: {sample_image.name}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(img)\n",
    "    axes[0, 0].set_title('Original')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Generate 7 augmented versions\n",
    "    aug_iter = datagen.flow(img_array, batch_size=1)\n",
    "    \n",
    "    for i, (row, col) in enumerate([(0,1), (0,2), (0,3), (1,0), (1,1), (1,2), (1,3)]):\n",
    "        if i >= 7:  # We want 7 augmented images\n",
    "            break\n",
    "        \n",
    "        aug_img = next(aug_iter)[0].astype('uint8')\n",
    "        axes[row, col].imshow(aug_img)\n",
    "        axes[row, col].set_title(f'Augmented {i+1}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüéØ Augmentation Parameters:\")\n",
    "    for param, value in aug_config.items():\n",
    "        if param != 'enabled':\n",
    "            print(f\"  {param}: {value}\")\n",
    "\n",
    "show_augmentation_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validation and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation\n",
    "print(\"‚úÖ Data Preprocessing Summary\")\n",
    "print(\"============================\")\n",
    "\n",
    "processed_path = Path('../data/processed')\n",
    "if processed_path.exists():\n",
    "    print(\"üìÅ Processed data structure:\")\n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        split_path = processed_path / split\n",
    "        if split_path.exists():\n",
    "            total_images = sum(len(list(class_dir.glob('*.jpg'))) \n",
    "                             for class_dir in split_path.iterdir() \n",
    "                             if class_dir.is_dir())\n",
    "            print(f\"  {split}/: {total_images} images\")\n",
    "            \n",
    "            for class_dir in split_path.iterdir():\n",
    "                if class_dir.is_dir():\n",
    "                    class_count = len(list(class_dir.glob('*.jpg')))\n",
    "                    print(f\"    {class_dir.name}/: {class_count} images\")\n",
    "    \n",
    "    print(\"\\nüöÄ Ready for Model Training!\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. üéØ Train the model:\")\n",
    "    print(\"   python ../scripts/train_model.py\")\n",
    "    print()\n",
    "    print(\"2. üì± Convert to TensorFlow Lite:\")\n",
    "    print(\"   python ../scripts/convert_to_tflite.py\")\n",
    "    print()\n",
    "    print(\"3. üìä Evaluate performance:\")\n",
    "    print(\"   python ../scripts/evaluate_model.py\")\n",
    "    \nelse:\n",
    "    print(\"‚ùå Processed data not found\")\n",
    "    print(\"Please run the preprocessing steps above successfully before proceeding.\")\n",
    "\n",
    "print(\"\\nüí° Tips:\")\n",
    "print(\"‚Ä¢ Monitor training in TensorBoard: tensorboard --logdir ../logs\")\n",
    "print(\"‚Ä¢ Adjust hyperparameters in ../configs/training_config.yaml\")\n",
    "print(\"‚Ä¢ Add more data if model performance is insufficient\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}